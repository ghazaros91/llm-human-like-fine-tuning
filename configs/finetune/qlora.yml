finetune:
  output_dir: "./outputs"
  batch_size: 4
  learning_rate: 2e-4
  epochs: 3
  sequence_length: 2048

  qlora:
    quantization:
      load_in_4bit: true           # enable 4-bit quantization for QLoRA
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: "nf4"   # nf4 is standard for QLoRA

